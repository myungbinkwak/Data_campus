{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('temp.jpg', <http.client.HTTPMessage at 0x2ad11e30358>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "urllib.request.urlretrieve('https://cdn.visitkorea.or.kr/img/call?cmd=VIEW&id=055c2edc-a624-4b63-8066-1551bc909bb9', 'temp.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실행종료\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import urllib\n",
    "import os\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://korean.visitkorea.or.kr/detail/rem_detail.do?cotid=3c1a0943-222c-4c05-8c96-aff576753602&con_type=10500')\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait_state = wait.until(EC.presence_of_element_located((By.ID, 'footer')))\n",
    "title = driver.find_element_by_id('topTitle').text\n",
    "img_list = driver.find_element_by_css_selector('div.box_txtPhoto').find_elements_by_tag_name('img')\n",
    "img_path = 'article_img/'+title\n",
    "try:\n",
    "    if not os.path.exists(img_path):\n",
    "        os.makedirs(img_path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for img in img_list:\n",
    "    src = img.get_attribute('src')\n",
    "    src_name = src.split('id=')[1]\n",
    "    save_img_path = img_path + '/' + src_name + '.jpg'\n",
    "    urllib.request.urlretrieve(src, save_img_path)\n",
    "    \n",
    "print('실행종료')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import urllib\n",
    "import os\n",
    "import time\n",
    "def scroll_down(driver):\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    time.sleep(1)\n",
    "def scroll_down1(driver):\n",
    "    driver.find_element_by_css_selector('body').send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://korean.visitkorea.or.kr/detail/rem_detail.do?cotid=3c1a0943-222c-4c05-8c96-aff576753602&con_type=10500')\n",
    "\n",
    "wait = WebDriverWait(driver, 10)   \n",
    "time.sleep(1)\n",
    "scroll_down1(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "query_txt = input('크롤링할 키워드는 무엇입니까?')\n",
    "path = 'C:\\\\Users\\\\USER\\\\Bigdata\\\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.maximize_window()\n",
    "driver.get('https://korean.visitkorea.or.kr/main/main.html')\n",
    "time.sleep(1)\n",
    "#driver.find_element_by_id('openSearchFormInput').click()\n",
    "element = driver.find_element_by_id('inp_search')\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(Keys.RETURN)\n",
    "delay=10\n",
    "url_list=[]\n",
    "try:\n",
    "    wait = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.CLASS_NAME, 'btn_last')))\n",
    "    page_box = driver.find_element_by_id('page_box')\n",
    "    last_page = page_box.find_element_by_class_name('btn_last').get_attribute(\"id\")\n",
    "    last_page = int(last_page)\n",
    "    for num in range(2,4):\n",
    "        time.sleep(1)\n",
    "        wait = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.CLASS_NAME, 'btn_last')))\n",
    "        \n",
    "        ul = driver.find_element_by_class_name('list_thumType')\n",
    "        content_list = driver.find_element_by_class_name('list_thumType')\n",
    "        content_list = content_list.find_elements_by_css_selector('li > div.area_txt')\n",
    "        for i in content_list:\n",
    "            try:\n",
    "                href = i.find_element_by_class_name('tit').find_element_by_css_selector('a').get_attribute('href')\n",
    "                url_list.append(href)    \n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "        page_box.find_element_by_id(num).click()\n",
    "    \n",
    "    content_list = []\n",
    "    for url in url_list:\n",
    "        try:\n",
    "            url = url.split('\\'')[1]\n",
    "            base_url='https://korean.visitkorea.or.kr/detail/rem_detail.do?cotid='\n",
    "            final_url = base_url + url\n",
    "            driver.get(final_url)\n",
    "            time.sleep(2)\n",
    "\n",
    "            title = driver.find_element_by_id('topTitle').text\n",
    "            try:\n",
    "                topAddr = driver.find_element_by_id('topAddr').text\n",
    "                addr = topAddr.split('\\n')[0]\n",
    "                date = topAddr.split('\\n')[1].split(':')[1].strip()\n",
    "            except:\n",
    "                addr = ''\n",
    "                date = topAddr.split('\\n')[0]\n",
    "            heart = driver.find_element_by_id('conLike').text\n",
    "            share = driver.find_element_by_id('conShare').text\n",
    "            view = driver.find_element_by_id('conRead').text\n",
    "\n",
    "            content_full = driver.find_elements_by_class_name('wrap_contView')\n",
    "            content = content_full[0].text\n",
    "\n",
    "            data = {'title' : title, 'addr': addr, \n",
    "                    'date':date, 'heart':heart, 'share':share,\n",
    "                   'view': view, 'content':content}\n",
    "            content_list.append(data)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "\n",
    "    df = pd.DataFramerame(content_list)\n",
    "    df.to_csv('여행지-상세내용.csv', encoding='utf-8')\n",
    "        \n",
    "        \n",
    "        \n",
    "except TimeoutException:\n",
    "    print(\"Timeout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크롤링할 키워드는 무엇입니까?봄여행\n",
      "실행종료\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import urllib\n",
    "import os\n",
    "\n",
    "\n",
    "query_txt = input('크롤링할 키워드는 무엇입니까?')\n",
    "path = 'chromedriver.exe'\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.maximize_window()\n",
    "driver.get('https://korean.visitkorea.or.kr/main/main.html')\n",
    "time.sleep(1)\n",
    "element = driver.find_element_by_id('inp_search')\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(Keys.RETURN)\n",
    "delay=10\n",
    "url_list=[]\n",
    "try:\n",
    "    wait = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.CLASS_NAME, 'btn_last')))\n",
    "    page_box = driver.find_element_by_id('page_box')\n",
    "    last_page = page_box.find_element_by_class_name('btn_last').get_attribute(\"id\")\n",
    "    last_page = int(last_page)\n",
    "    for num in range(2, 4):\n",
    "        time.sleep(1)\n",
    "        wait = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.CLASS_NAME, 'btn_last')))\n",
    "        \n",
    "        ul = driver.find_element_by_class_name('list_thumType')\n",
    "        content_list = driver.find_element_by_class_name('list_thumType')\n",
    "        content_list = content_list.find_elements_by_css_selector('li > div.area_txt')\n",
    "        for i in content_list:\n",
    "            try:\n",
    "                href = i.find_element_by_class_name('tit').find_element_by_css_selector('a').get_attribute('href')\n",
    "                url_list.append(href)    \n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "        page_box.find_element_by_id(num).click()\n",
    "    url_list = list(set(url_list))\n",
    "    content_list = []\n",
    "    for url in url_list:\n",
    "        try:\n",
    "            url = url.split('\\'')[1]\n",
    "            base_url='https://korean.visitkorea.or.kr/detail/rem_detail.do?cotid='\n",
    "            final_url = base_url + url\n",
    "            driver.get(final_url)\n",
    "            time.sleep(2)\n",
    "\n",
    "            title = driver.find_element_by_id('topTitle').text\n",
    "            try:\n",
    "                topAddr = driver.find_element_by_id('topAddr').text\n",
    "                addr = topAddr.split('\\n')[0]\n",
    "                date = topAddr.split('\\n')[1].split(':')[1].strip()\n",
    "            except:\n",
    "                addr = ''\n",
    "                date = topAddr.split('\\n')[0]\n",
    "            heart = driver.find_element_by_id('conLike').text\n",
    "            share = driver.find_element_by_id('conShare').text\n",
    "            view = driver.find_element_by_id('conRead').text\n",
    "\n",
    "            content_full = driver.find_elements_by_class_name('wrap_contView')\n",
    "            content = content_full[0].text\n",
    "\n",
    "            data = {'title' : title, 'addr': addr, \n",
    "                    'date':date, 'heart':heart, 'share':share,\n",
    "                   'view': view, 'content':content}\n",
    "            content_list.append(data)\n",
    "            \n",
    "            img_list = driver.find_element_by_css_selector('div.box_txtPhoto').find_elements_by_tag_name('img')\n",
    "            img_path = 'article_img/'+title\n",
    "            try:\n",
    "                if not os.path.exists(img_path):\n",
    "                    os.makedirs(img_path)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            for img in img_list:\n",
    "                src = img.get_attribute('src')\n",
    "                src_name = src.split('id=')[1]\n",
    "                save_img_path = img_path + '/' + src_name + '.jpg'\n",
    "                urllib.request.urlretrieve(src, save_img_path)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "\n",
    "    df = pd.DataFrame(content_list)\n",
    "    df.to_csv('여행지-상세내용1.csv', encoding='euc-kr')\n",
    "        \n",
    "        \n",
    "        \n",
    "except TimeoutException:\n",
    "    print(\"Timeout\")\n",
    "    \n",
    "print('실행종료')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "구글 사이트에서 이미지를 검색하여 수집하는 크롤러 입니다.\n",
      "----------------------------------------------\n",
      "1.크롤링할 이미지의 키워드는 무업입니까? : 샴고양이\n",
      "2. 크롤링 할 건수는 몇건입니까? : 100\n",
      "3. 파일이 저장될 경로만 쓰세요(예:c:\\temp\\) : C:\\temp\\\n",
      "이미지 저장완료\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import urllib\n",
    "import os\n",
    "import time\n",
    "\n",
    "def scroll_down(driver):\n",
    "    driver.find_element_by_css_selector('body').send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "\n",
    "print('----------------------------------------------')\n",
    "print('구글 사이트에서 이미지를 검색하여 수집하는 크롤러 입니다.')\n",
    "print('----------------------------------------------')\n",
    "keyword = input('1.크롤링할 이미지의 키워드는 무업입니까? : ')\n",
    "num = int(input('2. 크롤링 할 건수는 몇건입니까? : '))\n",
    "path = input('3. 파일이 저장될 경로만 쓰세요(예:c:\\\\temp\\\\) : ')\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.google.com')\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait_state = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'gLFyf')))\n",
    "\n",
    "driver.find_element_by_class_name('gLFyf.gsfi').send_keys(keyword)\n",
    "driver.find_element_by_class_name('gLFyf.gsfi').send_keys(Keys.RETURN)\n",
    "\n",
    "menu_bar = driver.find_element_by_css_selector('div.MUFPAc')\n",
    "menu_list = menu_bar.find_elements_by_css_selector('div.hdtb-mitem')\n",
    "for menu in menu_list:\n",
    "    if menu.text == '이미지':\n",
    "        menu.click()\n",
    "        break\n",
    "        \n",
    "time.sleep(1)\n",
    "image_url_list = []\n",
    "while True:\n",
    "    if len(image_url_list) == num:\n",
    "        break\n",
    "    \n",
    "    image_box = driver.find_element_by_id('islmp')\n",
    "    image_list = image_box.find_elements_by_tag_name('img')\n",
    "    for image in image_list:\n",
    "        src = image.get_attribute('src')\n",
    "        image_url_list.append(src)\n",
    "    \n",
    "    if len(image_url_list) > num:\n",
    "        image_url_list = image_url_list[:num]\n",
    "\n",
    "    \n",
    "    scroll_down(driver)\n",
    "    scroll_down(driver)\n",
    "    scroll_down(driver)\n",
    "    \n",
    "    \n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "except:\n",
    "    pass\n",
    "count = 1\n",
    "for url in image_url_list:\n",
    "    save_img_path = path + '/' + str(count) + '.jpg'\n",
    "    opener = urllib.request.build_opener()\n",
    "    opener.addheaders = [('User-Agent','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1941.0 Safari/537.36')]\n",
    "    urllib.request.install_opener(opener)\n",
    "    urllib.request.urlretrieve(url, save_img_path)\n",
    "    count += 1\n",
    "    \n",
    "print('이미지 저장완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "def GetPaulBassettAddressList(driver):\n",
    "    driver.get('https://www.baristapaulbassett.co.kr/store/Store.pb')\n",
    "    shop_list = driver.find_elements_by_css_selector('#shopList > li')\n",
    "\n",
    "    address_list = []\n",
    "    for shop in shop_list:\n",
    "        address = shop.find_element_by_tag_name('address')\n",
    "        address_list.append(address.text)\n",
    "\n",
    "    return address_list\n",
    "def GetCafe10000LabAddressList(driver):\n",
    "    address_list = []\n",
    "    for i in range(1,16):\n",
    "        driver.get('https://www.10000lab.com/59/?sort=TIME&keyword_type=all&page=' + str(i))\n",
    "        map_list = driver.find_elements_by_css_selector('div.map-list-detail > div.map_container')\n",
    "        for map_data in map_list:\n",
    "            address = driver.find_element_by_css_selector('div.p_group  > p.adress')\n",
    "            address_list.append(address.text)\n",
    "    return address_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['경기도 오산시 세마동 독산성로', '경기도 오산시 세마동 독산성로', '경기도 오산시 세마동 독산성로', '경기도 오산시 세마동 독산성로', '경기도 오산시 세마동 독산성로', '경기도 오산시 세마동 독산성로', '경기도 오산시 세마동 독산성로', '경기도 오산시 세마동 독산성로', '경기도 오산시 세마동 독산성로', '경기도 오산시 세마동 독산성로', '경기도 평택시 비전동 1098-1', '경기도 평택시 비전동 1098-1', '경기도 평택시 비전동 1098-1', '경기도 평택시 비전동 1098-1', '경기도 평택시 비전동 1098-1', '경기도 평택시 비전동 1098-1', '경기도 평택시 비전동 1098-1', '경기도 평택시 비전동 1098-1', '경기도 평택시 비전동 1098-1', '경기도 평택시 비전동 1098-1', '경기도 남양주시 진접읍 해밀예당2로', '경기도 남양주시 진접읍 해밀예당2로', '경기도 남양주시 진접읍 해밀예당2로', '경기도 남양주시 진접읍 해밀예당2로', '경기도 남양주시 진접읍 해밀예당2로', '경기도 남양주시 진접읍 해밀예당2로', '경기도 남양주시 진접읍 해밀예당2로', '경기도 남양주시 진접읍 해밀예당2로', '경기도 남양주시 진접읍 해밀예당2로', '경기도 남양주시 진접읍 해밀예당2로', '경기도 김포시 태장로 751', '경기도 김포시 태장로 751', '경기도 김포시 태장로 751', '경기도 김포시 태장로 751', '경기도 김포시 태장로 751', '경기도 김포시 태장로 751', '경기도 김포시 태장로 751', '경기도 김포시 태장로 751', '경기도 김포시 태장로 751', '경기도 김포시 태장로 751', '서울특별시 금천구 가산동 가산디지털2로 173', '서울특별시 금천구 가산동 가산디지털2로 173', '서울특별시 금천구 가산동 가산디지털2로 173', '서울특별시 금천구 가산동 가산디지털2로 173', '서울특별시 금천구 가산동 가산디지털2로 173', '서울특별시 금천구 가산동 가산디지털2로 173', '서울특별시 금천구 가산동 가산디지털2로 173', '서울특별시 금천구 가산동 가산디지털2로 173', '서울특별시 금천구 가산동 가산디지털2로 173', '서울특별시 금천구 가산동 가산디지털2로 173', '경기도 의정부시 오목로 205 번길 1', '경기도 의정부시 오목로 205 번길 1', '경기도 의정부시 오목로 205 번길 1', '경기도 의정부시 오목로 205 번길 1', '경기도 의정부시 오목로 205 번길 1', '경기도 의정부시 오목로 205 번길 1', '경기도 의정부시 오목로 205 번길 1', '경기도 의정부시 오목로 205 번길 1', '경기도 의정부시 오목로 205 번길 1', '경기도 의정부시 오목로 205 번길 1', '경기도 안양시 동안구 관양동 부림로 121', '경기도 안양시 동안구 관양동 부림로 121', '경기도 안양시 동안구 관양동 부림로 121', '경기도 안양시 동안구 관양동 부림로 121', '경기도 안양시 동안구 관양동 부림로 121', '경기도 안양시 동안구 관양동 부림로 121', '경기도 안양시 동안구 관양동 부림로 121', '경기도 안양시 동안구 관양동 부림로 121', '경기도 안양시 동안구 관양동 부림로 121', '경기도 안양시 동안구 관양동 부림로 121', '인천광역시 서구 검단1동 완정로 39', '인천광역시 서구 검단1동 완정로 39', '인천광역시 서구 검단1동 완정로 39', '인천광역시 서구 검단1동 완정로 39', '인천광역시 서구 검단1동 완정로 39', '인천광역시 서구 검단1동 완정로 39', '인천광역시 서구 검단1동 완정로 39', '인천광역시 서구 검단1동 완정로 39', '인천광역시 서구 검단1동 완정로 39', '인천광역시 서구 검단1동 완정로 39', '대구광역시 달서구 죽전동 273-6', '대구광역시 달서구 죽전동 273-6', '대구광역시 달서구 죽전동 273-6', '대구광역시 달서구 죽전동 273-6', '대구광역시 달서구 죽전동 273-6', '대구광역시 달서구 죽전동 273-6', '대구광역시 달서구 죽전동 273-6', '대구광역시 달서구 죽전동 273-6', '대구광역시 달서구 죽전동 273-6', '대구광역시 달서구 죽전동 273-6', '인천광역시 계양구 계산4동 계양문화로 90', '인천광역시 계양구 계산4동 계양문화로 90', '인천광역시 계양구 계산4동 계양문화로 90', '인천광역시 계양구 계산4동 계양문화로 90', '인천광역시 계양구 계산4동 계양문화로 90', '인천광역시 계양구 계산4동 계양문화로 90', '인천광역시 계양구 계산4동 계양문화로 90', '인천광역시 계양구 계산4동 계양문화로 90', '인천광역시 계양구 계산4동 계양문화로 90', '인천광역시 계양구 계산4동 계양문화로 90', '경기도 부천시 원미구 중1동 소향로 131', '경기도 부천시 원미구 중1동 소향로 131', '경기도 부천시 원미구 중1동 소향로 131', '경기도 부천시 원미구 중1동 소향로 131', '경기도 부천시 원미구 중1동 소향로 131', '경기도 부천시 원미구 중1동 소향로 131', '경기도 부천시 원미구 중1동 소향로 131', '경기도 부천시 원미구 중1동 소향로 131', '경기도 부천시 원미구 중1동 소향로 131', '경기도 부천시 원미구 중1동 소향로 131', '서울특별시 종로구 사직동 새문안로5길 19', '서울특별시 종로구 사직동 새문안로5길 19', '서울특별시 종로구 사직동 새문안로5길 19', '서울특별시 종로구 사직동 새문안로5길 19', '서울특별시 종로구 사직동 새문안로5길 19', '서울특별시 종로구 사직동 새문안로5길 19', '서울특별시 종로구 사직동 새문안로5길 19', '서울특별시 종로구 사직동 새문안로5길 19', '서울특별시 종로구 사직동 새문안로5길 19', '서울특별시 종로구 사직동 새문안로5길 19', '경상남도 창원시 성산구 사파동 창이대로684번길 2', '경상남도 창원시 성산구 사파동 창이대로684번길 2', '경상남도 창원시 성산구 사파동 창이대로684번길 2', '경상남도 창원시 성산구 사파동 창이대로684번길 2', '경상남도 창원시 성산구 사파동 창이대로684번길 2', '경상남도 창원시 성산구 사파동 창이대로684번길 2', '경상남도 창원시 성산구 사파동 창이대로684번길 2', '경상남도 창원시 성산구 사파동 창이대로684번길 2', '경상남도 창원시 성산구 사파동 창이대로684번길 2', '경상남도 창원시 성산구 사파동 창이대로684번길 2', '서울특별시 강남구 역삼2동 선릉로69길 19', '서울특별시 강남구 역삼2동 선릉로69길 19', '서울특별시 강남구 역삼2동 선릉로69길 19', '서울특별시 강남구 역삼2동 선릉로69길 19', '서울특별시 강남구 역삼2동 선릉로69길 19', '서울특별시 강남구 역삼2동 선릉로69길 19', '서울특별시 강남구 역삼2동 선릉로69길 19', '서울특별시 강남구 역삼2동 선릉로69길 19', '서울특별시 강남구 역삼2동 선릉로69길 19', '서울특별시 강남구 역삼2동 선릉로69길 19', '서울특별시 영등포구 문래동3가 55-20', '서울특별시 영등포구 문래동3가 55-20']\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "#PaulBassettAddressList = GetPaulBassettAddressList(driver)\n",
    "#Cafe10000LabAddressList = GetCafe10000LabAddressList(driver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
